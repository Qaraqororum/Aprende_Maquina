{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c14ebe1b",
   "metadata": {},
   "source": [
    "# Ejercicio B1\n",
    "Miguel Hortelano Busto y Francisco Olayo González Rodríguez "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd64334",
   "metadata": {},
   "source": [
    "Como para estos clústerings resultantes, al no tener un conjunto de etiquetas verdaderas \"Ground Truth\", utilizamos métricas que no necesiten de ella. En nuestro caso optaremos por los coeficientes de siluteta (silhouette). También es oportuno"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5d7555",
   "metadata": {},
   "source": [
    "Carga de paquetes a utilizar en el entregable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca97f398",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import support_functions as sp\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split , GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "from sklearn.cluster import KMeans, SpectralClustering\n",
    "from sklearn.metrics import  confusion_matrix , cohen_kappa_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55078d72",
   "metadata": {},
   "source": [
    "1. Usar algún algoritmo de clustering sobre todos los datos sin emplear las etiquetas para obtener una primera clasificación. Definir una estrategia para clasificar nuevos ejemplos y obtener el mapa de clasificación final de toda la imagen. Obviamente, al no haber empleado las etiquetas de las clases puede que nuestro mapa de clasificación basado en clustering no tenga mucha relación con las clases predefinidas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828eea5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b5e57929",
   "metadata": {},
   "source": [
    "2. Para aplicar algoritmos de aprendizaje supervisado simularemos la escasez de muestras etiquetadas empleando solo 5000 muestras con sus etiquetas. Sin embargo, la selección de estas muestras no la vamos a hacer de forma aleatoria sino que vamos a emplear algoritmos de clustering para reducir el número de muestras pero preservando la distribución de los datos de entrada y de las clases definidas.  Primero, separar los datos en función de su etiqueta de clase. En cada subconjunto, aplicar algún algoritmo de clustering y definir una estrategia para obtener un subconjunto reducido que sea representativo del conjunto inicial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790be5a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d442e128",
   "metadata": {},
   "source": [
    "3. Utilizar algoritmos supervisados sobre el conjunto reducido de entrenamiento para obtener la clasificación de la imagen. Se debe obtener una aproximación del error de clasificación en test utilizando una partición del conjunto de entrenamiento. Se pueden obtener también resultados cualitativos representado las imágenes de clasificación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b7706e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tree classifier ##\n",
    "\n",
    "criterion = 'gini'\n",
    "max_depth = None\n",
    "report = metrics.confusion_matrix\n",
    "report2 = metrics.cohen_kappa_score\n",
    "\n",
    "Xtr, Xts, ytr, yts = train_test_split(X_reduced, Y_reduced, test_size=0.3)\n",
    "\n",
    "\n",
    "tree = DecisionTreeClassifier(criterion=criterion)\n",
    "tree.fit(Xtr, ytr)\n",
    "ytree = tree.predict(Xts)\n",
    "\n",
    "# Evaluate and compare results\n",
    "print('Confusion Matrix:  ', report(yts, ytree),'Cohen-kappa', report2(yts, ytree))\n",
    "\n",
    "Conf_matrix_tree = report(yts, ytree)\n",
    "Kappa_tree = report2(yts, ytree)\n",
    "sp.draw_ROC(yts,tree.predict_proba(Xts),tag_list)\n",
    "sp.draw_ConfusionM(Conf_matrix_tree,tag_list)\n",
    "\n",
    "\n",
    "X,a,a,a = sp.aviris_data_load()\n",
    "image = tree.predict(X.reshape([145*145,220]))\n",
    "sp.draw_image(image,\"Árbol de clasificación\")\n",
    "\n",
    "#%% Plot and save confusion matrix\n",
    "metrics = [Conf_matrix_tree, Conf_matrix_RF]\n",
    "for i in metrics:\n",
    "\n",
    "    ax = sns.heatmap(i, annot=True, cmap='Blues')\n",
    "\n",
    "    ax.set_title('Seaborn Confusion Matrix with labels\\n\\n');\n",
    "    ax.set_xlabel('\\nPredicted Values')\n",
    "    ax.set_ylabel('Actual Values ');\n",
    "\n",
    "    ## Display the visualization of the Confusion Matrix.\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f5b242",
   "metadata": {},
   "outputs": [],
   "source": [
    "## KNN clasiffier ##\n",
    "X_reduced, Y_reduced = sp.data_reducer()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_reduced, Y_reduced, stratify=Y_reduced,random_state=1)\n",
    "#%% KNN\n",
    "tag_list = np.arange(1,17)\n",
    "\n",
    "modelo = KNeighborsClassifier(n_neighbors=4,\n",
    "                              weights='distance',\n",
    "                              algorithm='auto',\n",
    "                              leaf_size=40, p=2,\n",
    "                              metric='cosine',\n",
    "                              metric_params=None,\n",
    "                              n_jobs=-1).fit(X_train,y_train)\n",
    "\n",
    "    \n",
    "pred = modelo.predict(X_test)\n",
    "score = modelo.predict_proba(X_test)\n",
    "\n",
    "conf_mat= confusion_matrix(y_test,pred)\n",
    "kappa= cohen_kappa_score(y_test,pred)\n",
    "print(kappa)\n",
    "    \n",
    "sp.draw_ROC(y_test,score,tag_list)\n",
    "\n",
    "sp.draw_ConfusionM(conf_mat,tag_list)\n",
    "\n",
    "#%% Imagen cualitativa\n",
    "X,a,a,a = sp.aviris_data_load()\n",
    "image = modelo.predict(X.reshape([145*145,220]))\n",
    "sp.draw_image(image,\"4NN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3c2db7",
   "metadata": {},
   "source": [
    "4. La imagen puede contener bandas con datos erróneos, o con bandas que tengan poca relevancia en el resultado de la clasificación. Utilizando métodos de clasificación que proporcionen un 'ranking' de características, intentar detectar y eliminar aquellas bandas que empeoran (o no mejoran) el resultado de la clasificación. De nuevo, dar un resultado cuantitativo del error en test, y cualitativo mediante la representación de mapas de clasificación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f70f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Entrenamiento del modelo para conseguir un ranking de características ##\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xl, Yl,random_state=1)\n",
    "\n",
    "extra_tree = ExtraTreeClassifier(random_state=0, splitter ='best' )\n",
    "\n",
    "clf = extra_tree.fit(X_train, y_train)\n",
    "\n",
    "score = clf.score(X_test, y_test)\n",
    "\n",
    "features = clf.feature_importances_\n",
    "\n",
    "plt.plot(features)\n",
    "plt.xlabel('Nº de bandas')\n",
    "plt.ylabel('Importancia')\n",
    "\n",
    "\n",
    "# Reducción de bandas o características\n",
    "\n",
    "#Hemos escogido este criterio de 0.01, para reducir las bandas menos importantes y, vemos que el resultado es bastante bueno\n",
    "indice= np.where(features< 0.01)\n",
    "\n",
    "X_reduced2 = np.delete(X_reduced, indice, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4214cde",
   "metadata": {},
   "source": [
    "5. Por último, empleando solo el conjunto reducido de muestras etiquetadas y las bandas seleccionadas, utilizar alguna estrategia de combinación de clasificadores (métodos 'ensemble') para intentar mejorar los resultados de la clasificación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad2645a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Random forest (ensembles) ##\n",
    "\n",
    "criterion = 'gini'\n",
    "max_depth = None\n",
    "report = confusion_matrix\n",
    "report2 = cohen_kappa_score\n",
    "\n",
    "\n",
    "Xtr, Xts, ytr, yts = train_test_split(X_reduced2, Y_reduced, test_size=0.3)\n",
    "# Train RF ensemble\n",
    "rf = RandomForestClassifier(n_estimators=200, criterion=criterion, random_state=100)\n",
    "rf.fit(Xtr, ytr)\n",
    "yb = rf.predict(Xts)\n",
    "\n",
    "# Evaluate and compare results\n",
    "print('Confusion Matrix:  ', report(yts, yb), 'Cohen-kappa',report2(yts, yb))\n",
    "\n",
    "Conf_matrix_RF = report(yts, yb)\n",
    "Kappa_RF = report2(yts, yb)\n",
    "\n",
    "#Observamos como con el conjunto reducido de bandas, dejando solo 16 bandas, el ensemble funciona\n",
    "#bastante bien con un cohen-kappa de ~0.74\n",
    "tag_list = np.arange(1,17)\n",
    "score = rf.predict_proba(Xts)\n",
    "sp.draw_ROC(yts,score,tag_list)\n",
    "\n",
    "sp.draw_ConfusionM(Conf_matrix_RF,tag_list)\n",
    "\n",
    "X_ = np.delete(X.reshape([145*145,220]), indice, axis=1)\n",
    "sp.draw_image(rf.predict(X_),\"Random Forest \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
